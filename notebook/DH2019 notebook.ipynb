{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook for settings generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urdubiometer as ubm\n",
    "from graphtransliterator import GraphTransliterator\n",
    "urduGT = GraphTransliterator.from_yaml_file(\"../../transliterate/urdu.yml\")\n",
    "scholarlyGT = GraphTransliterator.from_yaml_file(\"../../transliterate/transliteration.yml\")\n",
    "hindiGT = GraphTransliterator.from_yaml_file('../../transliterate/devanagari.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "audio_filename = '../audio/faiz_bol.wav'\n",
    "dat_target = '../waveform/faiz_bol.dat'\n",
    "json_target = '../waveform/faiz_bol.json'\n",
    "os.system('audiowaveform -i %s -o %s --pixels-per-second 20 --bits 8' % (audio_filename, dat_target))\n",
    "os.system('audiowaveform -i %s -o %s' % (dat_target, json_target))\n",
    "def normalize_waveform(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    json_content = json.loads(file_content)\n",
    "    data = json_content[\"data\"]\n",
    "\n",
    "    max_val = float(max(data))\n",
    "    new_data = []\n",
    "    for x in data:\n",
    "        new_data.append(x/max_val)\n",
    "\n",
    "    json_content[\"data\"] = new_data\n",
    "    file_content = json.dumps(json_content)\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(file_content)\n",
    "    return json_content\n",
    "waveform = normalize_waveform(json_target)\n",
    "#audiowaveform -i long_clip.mp3 -o long_clip.dat --pixels-per-second 20 --bits 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = '''bol kih lab aazaad hai;n tere\n",
    "bol zabaa;n ab tak terii hai\n",
    "teraa sutvaa;n jism hai teraa\n",
    "bol kih jaa;n ab tak terii hai\n",
    "dekh kih aahangar kii dukaa;n me;n\n",
    "tund hai;n shole sur;x hai aahan\n",
    "khulne lage quflo;n ke dahaane\n",
    "phailaa har ik zanjiir kaa daaman\n",
    "bol yih tho;raa vaqt bahut hai\n",
    "jism-o-zabaa;n kii maut se pahle\n",
    "bol kih sach zindah hai ab tak\n",
    "bol jo kuchh kahnaa hai kah le'''.split('\\n')\n",
    "\n",
    "lines_en = '''Speak, for your lips are free\n",
    "Speak, for your tongue is still yours\n",
    "Your long-suffering body is yours\n",
    "Speak, for your life is still your own\n",
    "Speak, for in the blacksmith's shop\n",
    "The flames are fierce, the iron red\n",
    "The mouths of locks have begun to open\n",
    "The skirt of every chain is outspread\n",
    "Speak, this little time is enough\n",
    "Before the death of the body and tongue\n",
    "Speak, for truth is still alive\n",
    "Speak, say what must be said\n",
    "'''.split(\"\\n\")\n",
    "\n",
    "lines_ur = [urduGT.transliterate(line) for line in lines]\n",
    "lines_trans = [scholarlyGT.transliterate(line) for line in lines]\n",
    "lines_hi = [hindiGT.transliterate(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_arab(token):\n",
    "    replacements = [ ('a', '^a'),\n",
    "                     ('i', '^i'),\n",
    "                     ('u', '^u'),\n",
    "                     ('ai', '^ai'),\n",
    "                     ('au', '^au'),\n",
    "                     ('uu', '^uu')]\n",
    "    for a, b in replacements:\n",
    "        if token == a:\n",
    "            token = b\n",
    "    return token\n",
    "def vocalize(line):\n",
    "\n",
    "    return ''.join([show_arab(token) for token in urduGT.tokenize(line)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanner = ubm.DefaultScanner(meters_list=[{'id':0, 'name': \"Faiz\", \"regex_pattern\": \"=(=|--)===(=|--)==\"}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans = [scanner.scan(line, graph_details=True)[0] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_of = {} # \"1\" -> verse 1\n",
    "\n",
    "for scan_id, scan in enumerate(scans):\n",
    "    labels = {'orig': [], 'en': [], 'ur': [], 'hi': []}\n",
    "    for match in scan.matches:\n",
    "        orig_tokens_str = ''.join(match.orig_tokens)\n",
    "        tokens_ur_w_arabs = ''.join([show_arab(_) for _ in match.orig_tokens])\n",
    "        labels['orig'].append(orig_tokens_str)\n",
    "        labels['en'].append(scholarlyGT.transliterate(orig_tokens_str).replace(\" \", \"·\"))\n",
    "        labels['ur'].append(urduGT.transliterate(tokens_ur_w_arabs).replace(\" \", \"\\u200f·\"))#//&#8207;\n",
    "        labels['hi'].append(hindiGT.transliterate(orig_tokens_str).replace(\" \", \"·\")   )\n",
    "    labels_of[scan_id+1] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = set()\n",
    "for scan in scans:\n",
    "    for match in scan.matches:\n",
    "        for _ in match.orig_tokens:\n",
    "            tokens.add(_)\n",
    "token_trans = {}\n",
    "vowels_to_mark = set(['a', 'i', 'u', 'ii', 'au', 'ai'])\n",
    "for token in tokens:\n",
    "    token_trans[token] = {}\n",
    "    \n",
    "    token_trans[token]['en'] = scholarlyGT.transliterate(token)\n",
    "    token_trans[token]['hi'] = hindiGT.transliterate(token)\n",
    "    if token in vowels_to_mark:\n",
    "        token_ur = '^' + token\n",
    "    else:\n",
    "        token_ur = token\n",
    "    token_trans[token]['ur'] = urduGT.transliterate(token_ur)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'lines': {\n",
    "        '_raw': lines,\n",
    "        'ur': lines_ur,\n",
    "        'en': lines_en,\n",
    "        'hi': lines_hi\n",
    "    },\n",
    "    'scans': {str(i+1):scan for i, scan in enumerate(scans)},\n",
    "    'labels_of': labels_of,\n",
    "    'token_trans': token_trans,\n",
    "    'base_graph': scanner._translation_graph.to_dict(),\n",
    "    'intervals': [[0.0, 4.125714285714288, 'cut'], [4.125714285714288, 7.023696449108615, '1'], [8.320000000000002, 11.080045966382015, '2'], [12.651428571428573, 14.756200484663541, '3'], [15.73714285714286, 18.601745013831568, '4'], [19.611428571428576, 22.33145999836452, '5'], [22.33145999836452, 25.150750820636258, '6'], [27.55428571428572, 29.721899445393763, '7'], [30.37714285714286, 32.40006797221399, '8'], [32.994285714285716, 35.62116334050255, '9'], [36.377142857142864, 38.444232142704514, '10'], [39.92, 41.99027150736831, '11'], [43.17714285714286, 46.39093568842475, '12'], [46.39093568842475, 51.2, 'cut']],\n",
    "    'peaks': waveform,\n",
    "    'audio_file': 'audio/faiz_bol.mp4'    \n",
    "}\n",
    "\n",
    "import json\n",
    "with open(\"../settings.js\", \"w\") as f:\n",
    "    f.write(\"settings=\"+json.dumps(settings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
